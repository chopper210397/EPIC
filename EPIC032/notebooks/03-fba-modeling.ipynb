{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca se importan las librerias que vas a usar\n",
    "import sys\n",
    "import os\n",
    "directory_path = os.path.abspath(os.path.join('..'))\n",
    "utils_path = os.path.abspath(os.path.join('../utils'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "    sys.path.append(utils_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "#from utils.Validator import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca se lee los archivos del modelamiento que deben estar en la siguiente ruta: \"../data/modeling/raw.csv\"\n",
    "df = pd.read_csv(r\"../data/modeling/03_train.csv\",sep=\"|\", dtype={'codunicocli_limpio':'str',})   \n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalon1. Poblacion sin riesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por definición conceptual se excluye los clientes con montos de remesas acumuladas por debajo de $200\n",
    "df00=df[df['MONTO_TOTAL']>=200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalon3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idenfica alertas en el 3er escalón - Directo a evaluación\n",
    "df0=df[(df['CTD_TRX']>=25) | (df['MONTO_TOTAL']>=20000)]\n",
    "df0[\"IF_LABEL\"]=3\n",
    "df0.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0.to_excel(r\"../reports/others/Salida_Elefantes.xlsx\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalon 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica a los clientes para la segmentación\n",
    "df1=df00[(df00['CTD_TRX']<25) & (df00['MONTO_TOTAL']<20000)]\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo: K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 0\n",
    "#Seleccion de variables para el modelo\n",
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'PORCENTAJE_MONTO']]\n",
    "ds=df2.sample(50000, random_state=1)\n",
    "data1_cluster = MinMaxScaler().fit_transform(ds)\n",
    "k = [2,3,4,5]\n",
    "for ki in k:\n",
    "        outputKMeans = KMeans(n_clusters = ki, init='k-means++', random_state = 7).fit(data1_cluster)\n",
    "        scoreSilhoutte = metrics.silhouette_score(data1_cluster, outputKMeans.labels_, metric='euclidean')  \n",
    "        print(\" k=\", ki,\" SC=\", scoreSilhoutte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "#Seleccion de variables para el modelo\n",
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'PORCENTAJE_MONTO', 'FLG_PERFIL']]\n",
    "ds=df2.sample(50000, random_state=1)\n",
    "data1_cluster = MinMaxScaler().fit_transform(ds)\n",
    "k = [2,3,4,5]\n",
    "for ki in k:\n",
    "        outputKMeans = KMeans(n_clusters = ki, init='k-means++', random_state = 7).fit(data1_cluster)\n",
    "        scoreSilhoutte = metrics.silhouette_score(data1_cluster, outputKMeans.labels_, metric='euclidean')  \n",
    "        print(\" k=\", ki,\" SC=\", scoreSilhoutte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "#Seleccion de variables para el modelo\n",
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'FLG_PERFIL']]\n",
    "ds=df2.sample(50000, random_state=1)\n",
    "data1_cluster = MinMaxScaler().fit_transform(ds)\n",
    "k = [2,3,4,5]\n",
    "for ki in k:\n",
    "        outputKMeans = KMeans(n_clusters = ki, init='k-means++', random_state = 7).fit(data1_cluster)\n",
    "        scoreSilhoutte = metrics.silhouette_score(data1_cluster, outputKMeans.labels_, metric='euclidean')  \n",
    "        print(\" k=\", ki,\" SC=\", scoreSilhoutte)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forsest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import step\n",
    "silhouette_list = []\n",
    "\n",
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'PORCENTAJE_MONTO', 'FLG_PERFIL']]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'PORCENTAJE_MONTO_SC', 'FLG_PERFIL_SC']] = scaler.fit_transform(df2)\n",
    "df2=df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'PORCENTAJE_MONTO_SC', 'FLG_PERFIL_SC']]\n",
    "df2\n",
    "\n",
    "ds=df2.sample(50000, random_state=1)\n",
    "\n",
    "for cont in np.arange(0.0001,0.0015,0.0003):\n",
    "    cluster_labels = IsolationForest(n_estimators = 500,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_features=(len(ds.columns)),\n",
    "                                    contamination=cont,\n",
    "                                    random_state=66).fit_predict(ds)\n",
    "    out_n = cluster_labels[cluster_labels==-1].shape[0]\n",
    "    sil = silhouette_score(ds,cluster_labels, metric='euclidean')\n",
    "    silhouette_list.append(sil)\n",
    "    print(\"silhouette for \"+str(np.round(cont,4))+\" with n=\" +str(out_n)+\" outliers is: \"+str(sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(n_estimators = 500,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_features=(len(df2.columns)),\n",
    "                                    contamination=0.0004,\n",
    "                                    random_state=66).fit_predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IF_LABEL']=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"IF_LABEL\"]==-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"IF_LABEL\"]==1].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'FLG_PERFIL']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']] = scaler.fit_transform(df2)\n",
    "df2=df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import step\n",
    "silhouette_list = []\n",
    "\n",
    "ds=df2.sample(50000, random_state=1)\n",
    "\n",
    "for cont in np.arange(0.0001,0.0015,0.0003):\n",
    "    cluster_labels = IsolationForest(n_estimators = 500,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_features=(len(ds.columns)),\n",
    "                                    contamination=cont,\n",
    "                                    random_state=66).fit_predict(ds)\n",
    "    out_n = cluster_labels[cluster_labels==-1].shape[0]\n",
    "    sil = silhouette_score(ds,cluster_labels, metric='euclidean')\n",
    "    silhouette_list.append(sil)\n",
    "    print(\"silhouette for \"+str(np.round(cont,4))+\" with n=\" +str(out_n)+\" outliers is: \"+str(sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Final\n",
    "model = IsolationForest(n_estimators = 500,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_features=(len(df2.columns)),\n",
    "                                    contamination=0.0001,\n",
    "                                    random_state=66).fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=model.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo de la silueta con toda la población\n",
    "sil = silhouette_score(df2,labels, metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el modelo\n",
    "import pickle\n",
    "pickle.dump(model, open(r\"../src/02_models/IF.model\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['IF_LABEL']=model.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"IF_LABEL\"]==-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"IF_LABEL\"]==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alertas según el modelo Isolations \n",
    "\n",
    "df3=df1[df1[\"IF_LABEL\"]==-1]\n",
    "\n",
    "#df3.to_excel(r\"../reports/others/Escalon22.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unimos las alertas del escalón 3 y 2\n",
    "alertas_tot=pd.concat([df0, df3], ignore_index=True)\n",
    "alertas_tot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
