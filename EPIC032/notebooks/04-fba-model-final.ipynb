{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca se importan las librerias que vas a usar\n",
    "import sys\n",
    "import os\n",
    "directory_path = os.path.abspath(os.path.join('..'))\n",
    "utils_path = os.path.abspath(os.path.join('../utils'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "    sys.path.append(utils_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "#from utils.Validator import *\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca leemos los datasets de entranamiento y test (creados en el preprocessing)\n",
    "train = pd.read_csv(r\"../data/modeling/03_train.csv\",sep=\"|\", dtype={'codunicocli_limpio':'str',})   \n",
    "test = pd.read_csv(r\"../data/modeling/03_test.csv\",sep=\"|\", dtype={'codunicocli_limpio':'str',}) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón1\n",
    "#Por definición conceptual se excluye los clientes con montos de remesas acumuladas por debajo de $200\n",
    "df00=train[train['MONTO_TOTAL']>=200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón3\n",
    "#Idenfica alertas en el 3er escalón - Directo a evaluación\n",
    "df0=train[(train['CTD_TRX']>=25) | (train['MONTO_TOTAL']>=20000)]\n",
    "df0[\"IF_LABEL\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón2\n",
    "# Identifica a los clientes para la segmentación\n",
    "df1=df00[(df00['CTD_TRX']<25) & (df00['MONTO_TOTAL']<20000)]\n",
    "df2 = df1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'FLG_PERFIL']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón1\n",
    "#Por definición conceptual se excluye los clientes con montos de remesas acumuladas por debajo de $200\n",
    "df_00=test[test['MONTO_TOTAL']>=200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón3\n",
    "#Idenfica alertas en el 3er escalón - Directo a evaluación\n",
    "df_0=test[(test['CTD_TRX']>=25) | (test['MONTO_TOTAL']>=20000)]\n",
    "df_0[\"IF_LABEL\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalón2\n",
    "# Identifica a los clientes para la segmentación\n",
    "df_1=df_00[(df_00['CTD_TRX']<25) & (df_00['MONTO_TOTAL']<20000)]\n",
    "df_2 = df_1[['MONTO_TOTAL', 'CTD_TRX', 'CTD_ORDENANTES', 'FLG_PERFIL']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Escalamiento de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca escalamos las variables en caso sea necesario\n",
    "\n",
    "#Train\n",
    "scaler = MinMaxScaler()\n",
    "df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']] = scaler.fit_transform(df2)\n",
    "df2=df2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']]\n",
    "df2\n",
    "\n",
    "#Test\n",
    "df_2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']] = scaler.fit_transform(df_2)\n",
    "df_2=df_2[['MONTO_TOTAL_SC', 'CTD_TRX_SC', 'CTD_ORDENANTES_SC', 'FLG_PERFIL_SC']]\n",
    "df_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca entrenamos el modelo final obtenido del noteebok \"modeling\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export .model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca exportamos el .model en la carpeta ../src/02_models/XXXXX.model\n",
    "\n",
    "model = pickle.load(open(r\"../src/02_models/IF.model\", 'rb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca exportamos el resultado de la inferencia del train y test en \n",
    "# - ../data/modeling/04_predicted_train.csv\n",
    "# - ../data/modeling/04_predicted_test.csv\n",
    "\n",
    "#Train\n",
    "df1['IF_LABEL']=model.predict(df2)\n",
    "#Alertas según el modelo Isolations \n",
    "df3=df1[df1[\"IF_LABEL\"]==-1]\n",
    "#Unimos las alertas del escalón 3 y 2\n",
    "alertas_train=pd.concat([df0, df3], ignore_index=True)\n",
    "alertas_train.to_csv(r\"../data/modeling/04_predicted_train.csv\",index=False,sep=\"|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alertas_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "df_1['IF_LABEL'] = model.predict(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "#Alertas según el modelo Isolations \n",
    "df_3=df_1[df_1[\"IF_LABEL\"]==-1]\n",
    "#Unimos las alertas del escalón 3 y 2\n",
    "alertas_test=pd.concat([df_0, df_3], ignore_index=True)\n",
    "alertas_test.to_csv(r\"../data/modeling/04_predicted_test.csv\",index=False,sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alertas_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8be246a0feeeca55854b079a196ff1dcc2150f1aacff6695489fd7b28db2cd65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
